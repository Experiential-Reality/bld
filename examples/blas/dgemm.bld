# dgemm: C = alpha*op(A)*op(B) + beta*C
# Pattern: nested parallel (outer dims) + sequential (inner reduction)
# The structure is the SAME on CPU and GPU - only the traverser differs

structure dgemm_

P transA: char
P transB: char
P m: int
P n: int
P k: int
P alpha: double
D A: m_times_k [input]
P lda: int [stride]
D B: k_times_n [input]
P ldb: int [stride]
P beta: double
D C: m_times_n [input, output]
P ldc: int [stride]

# Boundaries: transposition modes, edge cases
B trans_mode: notrans | trans
B empty: dims_zero | valid
B skip: alpha_zero_beta_one | compute

# The key insight: C[i,j] = sum_k(A[i,k] * B[k,j])
# Outer loops (i,j) are parallel (deps=0)
# Inner loop (k) is sequential reduction (deps=1)

L scale_C: C -> C (deps=0)
L matmul: A -> C (deps=1)

returns: void
